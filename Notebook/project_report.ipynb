{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de30897",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0efec; color: #14334a ; padding: 20px; border-radius: 20px; font-family: sans-serif; font-size: 14px\">\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"../Images/logo.png\" alt=\"RetroChem Logo\" style=\"max-width: 100%; height: auto;\">\n",
    "\n",
    "# Introduction \n",
    "\n",
    "The following Jupyter notebook briefly presents RetroChem, a pip-installable Python package designed for retrosynthetic analysis. This package was developed to assist chemists and chemical engineers in predicting possible synthetic pathways for target molecules, using a machine learning model trained on the USPTO_50K database. Retrosynthesis is a central concept in organic chemistry, enabling the design of efficient synthetic routes by working backward from the desired product.\n",
    "\n",
    "This package was created as a collaborative project for the EPFL course Practical Programming in Chemistry. [![GitHub3](https://img.shields.io/badge/EPFL-CH200-red.svg)](https://edu.epfl.ch/studyplan/en/bachelor/chemistry-and-chemical-engineering/coursebook/practical-programming-in-chemistry-CH-200)\n",
    "\n",
    "Before diving into the code and functionalities of the package, let’s briefly explore the motivations and core concepts that shaped its development.\n",
    "\n",
    "# How Retrochem came to mind\n",
    "\n",
    "The idea for RetroChem emerged from our shared interest in organic synthesis and the growing importance of computational tools in modern chemistry. During our organic chemistry courses and laboratories we often encountered the challenge of synthesizing a target molecule from known reactants, a task that both requires extensive expertise in chemistry and is also very time consuming. \n",
    "\n",
    "At first, we envisioned RetroChem as a tool that would search through a large database of known reactions, both organic and inorganic, to identify possible transformations for a given target molecule. The idea was to use the most comprehensive reaction datasets available and search whether a synthesis existed for the molecule in question.\n",
    "\n",
    "However, we quickly realized the scale of this task. The chemical universe is immensely large: it’s estimated there are up to 10⁶⁰ possible compounds. Even the most complete databases, such as CAS, which contains over 70 million registered compounds, are just a small fraction of that space. Searching such a large database for each input would not only be computationally intensive, potentially taking multiple minutes for even simple queries, but also fundamentally limited in scope.\n",
    "\n",
    "This insight led us to turn toward machine learning. Instead of exhaustively searching for known reactions, we decided to train a model that could generalize from reaction data and predict retrosynthetic steps based on learned patterns. This approach allows RetroChem to make educated predictions even for molecules it has never seen before. \n",
    "\n",
    "# Step 1: Training the model\n",
    "\n",
    "* Data Loading: We started by loading three preprocessed datasets (train, validation, test) based on the USPTO-50K reaction dataset. Each file includes cleaned reaction SMILES and their corresponding template identifiers.\n",
    "* Data Merging: These datasets were merged into a single file (combined_data.csv) while removing duplicate entries based on a unique reaction hash.\n",
    "* Fingerprint Generation: Using RDKit, the reactants and products were converted into Morgan fingerprints (radius 3, 2048 bits). Each valid molecule contributes one fingerprint vector.\n",
    "* Label Preparation: The reaction templates were encoded into numerical labels using LabelEncoder, ensuring compatibility with scikit-learn models.\n",
    "* Dataset Splitting: The data was split into training (70%), validation (15%), and test (15%) sets. Rare templates (those with fewer than two examples) were added only to the training set to preserve balance.\n",
    "* Normalization: The input vectors were standardized using StandardScaler to help the neural network learn more effectively.\n",
    "* Model Training: A multi-layer perceptron (MLPClassifier from scikit learn library) was trained with three hidden layers. Early stopping was used to prevent overfitting, and training progress was monitored using the loss curve.\n",
    "* Evaluation: The model was evaluated on both the validation and test sets using accuracy as the main metric.\n",
    "* Saving Outputs: Finally, the trained model, along with the scaler and label encoder, were saved to disk for use in future prediction steps.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RetroChem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
